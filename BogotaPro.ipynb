{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGdpjC3d97wy"
      },
      "source": [
        "Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsZajgVmDAFP",
        "outputId": "cdf48b94-9bfb-43ab-c08d-87cb7e80d1b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eljp2x4EDkqG",
        "outputId": "9e93bd66-9461-4c3b-9a2a-bdbf8a543c5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text) (0.13.0)\n",
            "Requirement already satisfied: tensorflow<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text) (2.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (1.22.4)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (0.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (0.4.8)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (2.12.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (3.20.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (1.16.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (2.12.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (0.32.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (67.7.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (16.0.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (1.14.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (4.5.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (2.3.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (3.8.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (2.12.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (1.54.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (23.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.13,>=2.12.0->tensorflow-text) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow<2.13,>=2.12.0->tensorflow-text) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow<2.13,>=2.12.0->tensorflow-text) (1.10.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (0.7.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (2.17.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (2.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (3.4.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (1.0.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (0.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (3.2.2)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-2.12.1\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2X46LPokHUc3"
      },
      "outputs": [],
      "source": [
        "!pip install xlsxwriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8ao-VxI2k5K",
        "outputId": "2b30880f-983d-4c70-d5fb-ae5fd57fef5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oVNZMYf0CSs"
      },
      "source": [
        "# Preparation\n",
        "- Create a function that create excel to hold the results of the models (Will be used later).\n",
        "- Extract the relevant data (the client sentences) from the dataset and hold it in a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGUwmtvbF77V"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        " \n",
        "def creating_excel() -> pandas.DataFrame:\n",
        "      # Create an Excel file\n",
        "      writer = pandas.ExcelWriter('Results.xlsx', engine='xlsxwriter')\n",
        "\n",
        "      # Set the column names\n",
        "      data = {'Sentence': [],'Category': [], 'Nouns': [] }\n",
        "\n",
        "      # Convert the dataframe to an XlsxWriter Excel object.\n",
        "      output_excel = pandas.DataFrame(data)\n",
        "      output_excel.to_excel(writer, sheet_name='Sheet1', index=False)\n",
        "      print('Excel Created')\n",
        "      return output_excel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-45XRDMAKmyr"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "from xlsxwriter import Workbook\n",
        "\n",
        "input_excel = pandas.read_excel('/content/drive/MyDrive/src/Chatbot dataset.xlsx') # data set\n",
        "\n",
        "client_message = [] # 377 sentence by client\n",
        "\n",
        "# rows num\n",
        "n_rows = len(input_excel.index)\n",
        "\n",
        "# columns num\n",
        "n_cols_ = len(input_excel.columns)\n",
        "\n",
        "for row in range(n_rows):\n",
        "  username = input_excel.iloc[row][2]\n",
        "  if username == 'client':\n",
        "    message = input_excel.iloc[row][3]\n",
        "    client_message.append(message)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGFkFeK79dyK"
      },
      "source": [
        "# Unsupervised  classification\n",
        "- First step: We use Named entity recognition with Bert module to get the nouns in the sentence.\n",
        "- Second Step: We use smaller-LaBSE(Language-agnostic BERT Sentence Embedding) model to get the sentences embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4151_4JyDW3W"
      },
      "source": [
        "# First step\n",
        "We use Named entity recognition with Bert module to get the nouns in the sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sV-OsoJT9_D_",
        "outputId": "b913fbf6-d855-4f3d-8b3c-26e240b612ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "all_sentence_nouns = [['places', 'students', 'building'], [], ['entrance', 'entrances', 'sides'], ['spaces', 'interaction', 'collaboration', 'amount', 'exchange', 'place'], ['methods', 'example', 'relationship', 'spaces', 'side', 'method', 'typology', 'floorplan', 'construction', 'methods', 'degree', '\\\\', 'permeability', '\\\\', 'concept'], ['building', 'heritage', 'university', 'account'], ['suggestions', 'case'], ['approach'], [], ['possibility', 'types', 'architecture'], ['architecture'], ['exatcly'], [], ['types', 'architecture', 'fabrication', 'printing'], ['parts', 'building', 'elements', 'processes'], [], ['use', 'space', 'building', 'interior', 'building', 'attention', 'use', 'materials', 'energy', 'building', 'spaces', 'entrances', 'courtyards', 'spaces', 'use', 'problem', 'lighting', 'building', 'glass', 'steel', 'structure', 'building', 'freedom', 'cooperation', 'friendliness'], ['problem'], [], [], ['building', 'society'], ['type', 'activities'], ['rooms', 'quality'], ['cafe', 'ground', 'floor'], ['Roof', 'garden', 'place', 'rest'], ['building'], ['seminar', 'rooms', 'office', 'rooms', 'lecture', 'halls', 'workshops', 'Cafe', 'music', 'room'], ['spaces', 'lecture', 'halls', 'study', 'rooms', 'Usage', 'space', 'way', 'parties', 'communities', 'example', 'spaces', 'spaces', 'philosophies', 'Openness', 'beauty', 'harmony'], [], ['opinion', 'points'], ['values', 'point'], [], ['spaces'], ['examples'], ['TUM', 'building'], ['Shelter', 'elements'], ['example', 'point'], ['words', 'example'], ['lot', 'light'], ['west'], ['buiding'], ['space', 'front', 'building'], ['architecture', 'buildings', 'scale'], ['somethig'], ['colors', 'sun'], ['architecture'], ['climate', 'ventilation'], ['entrance', 'hall', 'meeting', 'point', 'students'], ['tables', 'porposes'], ['strairs', 'front', 'building', 'scene', 'events', 'concerts'], ['trees', 'plants', 'shadows'], ['design'], [], ['spaces', 'building'], ['playground'], ['garden'], ['building'], ['classrooms'], [], ['building'], [], [], ['building', 'impact', 'community', 'environment'], [], ['color'], ['Yellow'], [], ['values', 'building'], ['space'], ['Students', 'space'], ['building'], ['building', 'impact', 'community', 'environment'], ['thoughts', 'building', 'impact'], ['spaces', 'building'], [], [], ['building'], ['student', 'need'], ['plan'], ['renovation'], [], ['studio', 'space'], [], ['community', 'space', 'students', 'cafe', 'course'], ['atrium', 'building'], [], ['materials'], ['construction', 'facade'], ['Hi', 'Zaha'], [], [], [], ['design', 'idea'], ['architecture'], ['teachers'], ['ideas'], ['entrances', 'spaces', 'areas'], [], ['roof', 'terrace', 'Cafe', 'part', 'school'], [], ['input'], [], ['Building', 'university', 'building', 'people', 'sqm', 'sqm', 'floors', 'floor', 'elevators', 'stairs'], [], [], ['opportunity', 'issues', 'campus'], ['student', 'architecture', 'faculty', 'buildings', 'spaces', 'lectures', 'lounge', 'space', 'ammenities', 'microwaves'], ['building', 'materials', 'building'], ['course', 'action', 'building', 'materials', 'site', 'design', 'resources'], ['Recycling', 'reuse'], ['thing', 'architecture', 'buildings', 'design', 'school'], ['building', 'loads', 'daylight'], ['idea', 'parts', 'building', 'prototype', 'research', 'TUM'], ['suggestion'], ['Architecture', 'students', 'environment'], ['sustainability', 'standards', 'must', 'Florian', 'Nagler', 'deal', 'research', 'topic'], ['timber', 'properties'], ['input'], ['Waht', 'project'], ['campus', 'slide', 'slide', 'coty', 'centre'], ['slide'], ['building', 'values', 'university', 'sake'], ['values', 'university'], [], [], [], ['lot', 'shops'], ['spaces'], ['lot', 'student'], ['toilets'], ['chat', 'teacher'], ['trees', 'grass'], ['trees'], ['spaces'], ['history'], ['history'], ['spaces'], ['trees', 'grass'], [], ['history'], ['street'], ['ground', 'floor'], ['shops', 'ground', 'floor'], [], ['glass'], ['glass'], [], [], [], ['building', 'spaces', 'group', 'works', 'models', 'cooperation', 'students', 'years', 'courses', 'rooms', 'group', 'work', 'squares', 'classes'], ['building', 'impact', 'architecture', 'spaces', 'floor', 'student', 'city', 'Munich', 'exhibition', 'events', 'architecture', 'world', 'cafè', 'library', 'space', 'students', 'projects', 'tables', 'nature', 'building', 'place', 'knowledge', 'materials', 'windows', 'facade', 'citizens', 'students', 'light', 'building', 'value', 'cooperation', 'modernity', 'creativity', 'knowledge'], ['building', 'mq'], ['wood', 'construction'], ['time'], ['building', 'stories'], ['care'], [], ['grade', 'roof'], ['architects', 'future'], ['building', 'conference', 'room', 'storage', 'room', 'student', 'representatives', 'gathering', 'point', 'cafeteria', 'library', 'content', 'feminism', 'sustainability', 'ground', 'floor', 'society', 'students', 'space', 'exhibitions', 'buidling', 'space', 'LGTBIAQ', '*', 'community', 'office', 'anti', 'racism', 'students', 'students', 'experiences', 'hopes', 'perspectives', 'buidling', 'footprint', 'materials', 'circularity', 'materials', 'materials', 'way', 'construction', 'functionality', 'sense', 'sustainability', 'flexibility', 'comfort', 'students'], ['suggestions', 'ideas'], ['improvements', 'ideas'], ['spaces', 'students'], ['building', 'space'], ['building', 'recyclabe', 'matierals'], ['building', 'students'], ['building', 'space'], ['student', 'disabilities'], ['building', 'space', 'people', 'nature'], ['Workshops', 'care', 'space'], [], ['spaces', 'flexibility'], [], [], ['hi', 'Zaha'], [], ['house'], ['design'], ['house', 'infill', 'material'], ['clt', 'construction'], ['insulation', 'house'], ['Germany'], ['insulation', 'frame'], ['concrete', 'infill'], ['structure'], ['column'], ['column', 'raster'], ['wood', 'column', 'apartment'], ['structure', 'detail', 'Sinnstiftung'], ['concrete'], ['aggregate'], ['aggregate', 'concrete'], ['Sinnstiftung'], ['advantage', 'clay', 'ceiling'], ['materials'], ['examples', 'house'], ['example', 'house'], ['Hi', 'Zaha'], ['sorry', 'idea'], ['studios', 'building', 'professor', 'student', 'time', 'zoom', 'meetings'], ['architecture', 'faculties', 'example', 'exhibition', 'spaces', 'ground', 'floor', 'cafe'], ['brick', 'appearance', 'building'], ['place', 'windows'], ['plaza', 'front'], ['greenery', 'building', 'realationship', 'nature'], ['design', 'block', 'access', 'points'], ['connections', 'buildings'], ['bridges'], ['student', 'gathering', 'areas'], ['seminar', 'rooms', 'people', 'building'], ['makerspace', 'model', 'making'], ['lecture', 'halls'], ['Wheelcahir', 'accesibility', 'building'], ['ideas'], ['Thank'], ['ideas'], ['consideration'], ['goal'], ['goal'], ['ideas'], [], ['idea'], ['Thank'], ['Hi', 'Zaha'], ['thanks'], ['light', 'space', 'Facilities', 'features', 'students', 'automats', 'drinks', 'food', 'drink', 'water', 'Spaces', 'group'], ['Yes', 'sustainability', 'equity', 'democracy'], [], ['Spaces', 'meetings', 'groups'], [], ['CODE'], [], ['reference', 'desin'], ['architecture', 'school', 'tables', 'lot', 'light', 'atelier'], ['space', 'core', 'building', 'ideas', 'networking', 'keypoints'], ['coffe', 'machine', 'part'], [], [], [], ['reference', 'design'], ['tile'], ['thanks', 'database', 'architects', 'works'], ['building', 'one'], ['Alvaro', 'Siza', 'Architect'], [], ['drawings'], ['past'], [], ['Zaha', 'Hadid', 'design', 'building'], ['Hello', 'Zaha', 'design', 'evaluation', 'opinion', 'faculty', 'building', 'couple', 'studio', 'spaces', 'professorship', 'Auer', 'Petzold', 'Dörfler', 'building', 'impact', 'environment', 'roof', 'system', 'building', 'cooling', 'heating', 'building', 'TUM', 'campus', 'building', 'Theresienstraße', 'Civil', 'Environmental', 'Engineers', 'Nordbau', 'connection', 'department', 'TUM', 'building', 'Stammgelände', 'TUM', 'architecture', 'faculty', 'building', 'place', 'coffee', 'building'], ['rooms', 'limitation'], ['environment'], [], ['idea'], ['glass', 'fassade'], ['values'], ['buildings', 'part', 'communicate'], [], ['finish'], ['building', 'community', 'space'], ['space', 'sky'], ['windows', 'studios'], ['Idea', '!'], ['meeting', 'zones', 'exchange'], ['places', 'kind', 'retreat', 'exchange'], ['materials', 'use', 'materials', 'reuse', 'materials', 'buildings'], ['building', 'spaces', 'workshop', 'students'], ['building', 'spaces', 'students', 'groups'], ['building', 'lecture', 'rooms', 'lectures', 'students'], ['building', 'seminar', 'rooms', 'lectures', 'groups', 'students'], ['design', 'building', 'styles'], ['construction', 'building', 'state', 'art', 'construction', 'technologies', 'Manufacturing', 'Construction'], ['building', 'energy', 'consumption'], ['construction', 'phase'], ['design', 'building', 'rethink', 'design'], ['floor', 'toilets'], [], [], ['budget'], ['users'], ['people'], ['students'], ['rooms'], ['cafeteria'], ['Nice'], ['architect', 'office', 'design'], ['Ahh'], ['projects'], ['example'], ['cities'], ['building', 'Munich'], [], ['building'], ['building'], ['rooftop', 'garden'], ['solutions', 'ones'], ['building'], ['DGNB', 'certificate'], ['internship', 'planning', 'process'], ['matter'], ['Stundentrooms', 'worshopspaces', 'necessity'], ['student', 'work', 'computers', 'model', 'work'], [], ['teams', 'collaboration', 'student', 'life', 'inputs', 'environments', 'meeting', 'points', 'coffee', 'stations', 'kitchens', 'things'], ['workstations'], ['workstations', 'use', 'concept', 'university'], [], ['teamwork', 'use', 'use', 'context'], ['structure', 'Reconstruction', 'lot', 'resources', 'building'], ['structure'], ['floors', 'building'], ['plants', 'building', 'plants', 'people'], ['building', 'building', 'building'], ['measurement', 'technology', 'energy'], ['panels', 'electricity'], ['percentage', 'electricity', 'panels'], ['panel', 'roof', 'space'], ['style', 'buildings'], ['rooms', 'building'], ['library', 'place'], ['wood', 'building'], ['control', 'system', 'lighting', 'heating', 'winter'], ['cooling', 'system'], ['building', 'air', '-', 'conditioner'], ['floor', 'heating'], ['ceiling', 'heating'], ['wall', 'heating'], ['office', 'room', 'classroom', 'sound', 'absorber'], [], ['building', 'spaces', 'students', 'time', 'interactions', 'addition', 'architecture'], ['sense'], ['floors', 'scale', 'building', 'context'], ['building', 'students', 'disabilities', 'studio', 'spaces', 'offices', 'staff'], ['project', 'materials', 'building', 'practices', 'building', 'way'], ['spaces', 'facilities', 'students', 'staff'], ['aesthetic', 'cityscape'], ['students', 'teaching', 'spaces'], ['floors', 'height', 'stairs', 'elevators'], ['m2'], ['canteen', 'spaces', 'people', 'food'], ['building', 'environment', 'discussion', 'sharing', 'ideas', 'form'], ['windows'], ['spaces', 'impact', 'student', 'population', 'community'], ['library'], ['inp', 'zaha', 'architectureut'], ['architecture'], ['teachers'], [], ['architect', 'building'], [], ['tonight'], ['beer'], ['hello'], [], ['architecture', 'school'], ['school', 'workshop', 'shops'], ['food'], ['Yes', 'access', 'toilet'], ['place', 'people', 'other'], ['city', 'landmark'], ['value', 'univesity'], ['studio', 'time'], ['thief'], ['block'], ['communication', 'neighbor'], ['ground', 'floor', 'realationship', 'street'], ['trees'], ['courtyard'], ['beauty', 'seasons'], ['space', 'history'], ['space'], ['spaces'], [], ['teachers', 'chat'], [], ['lot', 'students'], []]\n",
            "client_message = ['\"I think there should be many various sitting and studying places for students, both inside and outside of the building.\"', '\"It should be distinctive but still matching to the surrounding.\"', '\"It should be clear where the entrance is and if possible, there should be multiple entrances from various sides.\"', '\"well I think that the spaces should be focused on interaction and collaboration... so the biggest amount of exchange can take place\"', '\"well it could be achieved through different methods. One, for example, could be the relationship between public and private spaces - leaning more to the public side. Another method could be through the typology of the floorplan and the construction methods implemented - meaning to have a high degree of \\\\\"permeability\\\\\" in the architectural concept \"', '\"yes, the current building, as unsuitable as it might be, represents the heritage of the university.. How do you think that can be taken into account? \"', '\"maybe, however Im interested in your suggestions... what do you suggest in this case?\"', '\"i find that a very correct approach... how did you learn about that?\"', '\"correct again \"', '\"well maybe it is a possibility to experiment about new types of architecture\"', '\"where did you learn about architecture?\"', '\"where exatcly?\"', '\"i see\"', '\"what types of experimental architecture that you find interesting... maybe digital fabrication and 3d printing?\"', '\"well if we intend to maintain ceratin parts of the existing building, then maybe the new elements can be elaborated with prefabricated or 3d printed processes \"', '\"\"', '\"hi, i think if there´s more free use co-working space in the building would be great. The interior of the building should pay attention to the use of more recycled materials and clean energy. Also, it would be great if the building could break up the interior and exterior spaces and have more entrances and courtyards, small spaces for free use. Considering the problem of lighting, perhaps the building can use more transparent glass and light steel structure. This building stands for freedom, cooperation, and environmental friendliness.\"', '\"no problem\"', '\"no\"', '\"thank you and bye\"', '\"The building should be more open for the society.\"', '\"It would be good to hold different type of activities here.\"', '\"The rooms should have good acoustic quality\"', '\"To have a cafe on the ground floor would be nice.\"', '\"Roof garden will be perfect place to have a rest.\"', '\"Can we make the building more sustainable?\"', '\"There should be 50 seminar rooms, 12 office rooms, 7 lecture halls, 2 workshops, a Cafe and a music room in it.\"', '\"1. open spaces, lecture halls, study rooms. 2. Usage of space in a way it might be shared with non university third parties of the communities. For example open spaces that might be used by anyone such as green spaces. 3. Should be representative of multiple architectural philosophies. 4. Openness, beauty, harmony\"', '\"good\"', '\"What is your opinion on points 1 and 4?\"', '\"Which of all values I mentioned in point 4 do you like the most?\"', '\"why?\"', '\"How would you design open spaces?\"', '\"Give me some examples\"', '\"How would you achieve this in the TUM building?\"', '\"Shelter from which elements?\"', '\"What do you think about the example i provided in the second point?\"', '\"Could you describe in your own words the example i provided?\"', '\"there should be a lot of natural light inside\"', '\"west-east\"', '\"to connect it with the existing buiding\"', '\"to create a public space in front of the building\"', '\"it should consider architecture of buildings nearby und have a humanic scale\"', '\"somethig natural and local\"', '\"light colors to reflect the sun\"', '\"minimalistic architecture\"', '\"it should be climate neutral or even positive. Can we provide a good natural ventilation?\"', '\"a big entrance hall with a meeting point for students\"', '\"and some tables that can be used by everybody for different porposes like studying or eating\"', '\"we can also have a strairs in front of the building to use it for sitting or like a scene for some events and small concerts\"', '\"and also trees and plants are important to provide shadows\"', '\"they can also be used in interior design\"', '\"\"', '\"What spaces should be in the building?\"', '\"I want a big playground.\"', '\"Can we have a garden?\"', '\"What should the building look like? \"', '\"How many classrooms will be\"', '\"20\"', '\"Where will the building be located?\"', '\"It is tooooo narrow\"', '\"I like that\"', '\"How can the building have a positive impact on the community and the environment?\"', '\"YES\"', '\"What will the color be like\"', '\"Yellow or gray\"', '\"Nothing\"', '\"What values should the building express?\"', '\"We need more free space \"', '\"Students need space to communicate\"', '\"What do you want to see in the building\"', '\"How can the building have a positive impact on the community and the environment? \"', '\"Do you have any thoughts about how the building can have a positive impact?\"', '\"What spaces should be in the building?\"', '\"How many?\"', '\"At least 30\"', '\"What should the building look like? \"', '\"consider the student\\'s need\"', '\"what\\'s your concrete plan?\"', '\"would there be any renovation\"', '\"okay looks good\"', '\"I think the studio space is not enoughand too difficult to find now. where would you build it?\"', '\"okay you repeat again\"', '\"It should be a community space were students can meet and hang out together. So it should have a cafe somewhere were you could meet up. Of course it would need \"', '\"maybe an atrium building?\"', '\"\"', '\"maybe looking into eco friendly materials \"', '\"could be a wooden construction with a wooden facade\"', '\"Hi Zaha\"', '\"How are you?\"', '\"What would you design there?\"', '\"Thats not enough\"', '\"What is your design idea?\"', '\"Where did you learn architecture?\"', '\"Who were your teachers?\"', '\"Are you so many lovely ideas\"', '\"Perhaps more accessible entrances larger public spaces more communal areas\"', '\"\"', '\"I really appreciate the roof terrace Cafe and I think it should be part of the new school as well\"', '\"Is that how what do you think about my\"', '\"What do you think about my input\"', '\"What would you like to know\"', '\"Building will be used as a university building, it should host 1400 people. It should be bigger than 3000 sqm, smaller than 5000 sqm. It should have 3-4 floors, each floor will be accessible with elevators and stairs.\"', '\"I guess so\"', '\"What now?\"', '\"I think this is a great opportunity address some of the issues the main campus has.\"', '\"As a student, I honestly do not feel welcomed in most of the architecture faculty\\'s buildings. There are very limited spaces to just hang out inbetween the lectures. I think we need a lounge space with some little ammenities like microwaves\"', '\"Do you know what they are planning to do with the building materials from the existing building?\"', '\"I do believe the first course of action should not be to demolish the building but refurbish it. If that is not possible we should reuse existing materials on site as much as possible and design based on those resources.\"', '\"Recycling is not nearly as effective as reuse, unfortunately\"', '\"Another thing that has always bothered me with the other architecture buildings is that they do not feel and look like a design school\"', '\"I would like for the new building to have loads of daylight\"', '\"And I think it could be a good idea to use parts of this building as a prototype for the various research that is done here at TUM\"', '\"Why do you like that suggestion?\"', '\"I agree! Architecture students should be inspired by the environment they\\'re in and learn from it\"', '\"I also believe building as simply as possible, while still complying with the high sustainability standards is a must. Florian Nagler has done a great deal of research into that topic\"', '\"I would love for it to be built out of timber, because of its ecological properties\"', '\"Do you not want any more input from me?\"', '\"Waht do you think of the project?\"', '\"Also, I know the Garching campus has a very fast and cool slide and I would love it if we get an even faster slide here in the coty centre as well\"', '\"Do you know of the slide in Garching?\"', '\"I think the building should reflect the values of the university, and not just be flashy for the sake of it\"', '\"What do you think are the values of the university?\"', '\"Thank you for putting up with me!\"', '\"new\"', '\"good \"', '\"a lot of shops \"', '\"spaces\"', '\"a lot of student\"', '\"toilets\"', '\"chat with teacher\"', '\"trees grass\"', '\"trees\"', '\"spaces\"', '\"history\"', '\"history\"', '\"spaces\"', '\"trees grass\"', '\"modern\"', '\"history\"', '\"open to street\"', '\"ground floor open\"', '\"and shops on ground floor\"', '\"not too high\"', '\"not too much glass \"', '\"not too much glass\"', '\"safe\"', '\"big \"', '\"safe\"', '\"The building should have several spaces for group works, especially for create models. It\\'s important to stimulate the cooperation between students of different years and courses creating rooms dedicated to the group work more similar to intern squares than classes. \"', '\"The building could have a positive a positive impact creating an architecture with public and semi public spaces on the bottom floor, opened for every student of the city of Munich where is possible to create temporary exhibition and events related to the architecture world. There has to be a cafè and a library but also an open space outside where students can work on projects on huge tables and being surrounded by nature. The building should look like a pacific place, that stimulate knowledge. So it should be modern, constructed with recycled materials and there should be several windows especially on the principal facade to permit to citizens to look inside and to the students to have as much natural light as possible. The building should express the value of cooperation, modernity, creativity and knowledge\"', '\"I think a building of 3000 mq is enough \"', '\"We could use recycled wood for the construction \"', '\"thank you for your time\"', '\"I would like to have it as a tall building with 20 stories \"', '\"I don\\'t care\"', '\"\"', '\"I want a grade on the roof\"', '\"Do you think ai will replace architects in the future? \"', '\"the building should include a conference room and storage room for the student representatives. also I could imagine a flexible and open gathering point, which could consists of a student-run cafeteria and a library, with more content regarding feminism and sustainability. it should include an open ground floor, where the urban society meets students: with space for changing and constant exhibitions. The buidling offers a safe space for the LGTBIAQ* community and has an office for anti-racism where students can help students and can exchange their experiences, hopes and perspectives. The buidling itself is built with a CO2-positive footprint, with local materials and considering the circularity of its materials. the materials and the way of construction should arise out of the functionality in sense of sustainability, flexibility and physical comfort for the students. \"', '\"do you have suggestions for my ideas?\"', '\"do you have improvements regarding my ideas?\"', '\"I think we need working spaces where students can work together\"', '\"I think the building should also have a space for hanging out\"', '\"The building should be made of recyclabe matierals\"', '\"The building should be easy to build, so students can build most of it themselves\"', '\"The building should maximize the space provided to be efficient\"', '\"It should be accessible for every student, also with disabilities\"', '\"I think the building should have an outdoor space to connect people with nature\"', '\"Workshops to take care of the outdoor space could be added\"', '\"Exactly!\"', '\"We should let spaces be big but able to separate to provide more flexibility\"', '\"\"', '\"I am done!\"', '\"hi Zaha\"', '\"What would you like to know\"', '\"how to build a half-timbered house\"', '\"i want a modern design\"', '\"I would like to build a modern half timbered house, what infill material should I use?\"', '\"I would like to use clt for the construction.\"', '\"How can I do the insulation of a half timbered house?\"', '\"I live in Germany.\"', '\"How should I connect the insulation and the frame?\"', '\"I want to use ultra lightweight concrete for the infill.\"', '\"How do I waterproof the structure？\"', '\"How can I 3d print a column?\"', '\"How thick should the column be with 5m raster?\"', '\"I would like to use wood column for a modern half timbered apartment.\"', '\"Can you show me the structure detail of the Sinnstiftung?\"', '\"Can I 3d print infra lightweight concrete?\"', '\"What aggregate should I use?\"', '\"What aggregate should I use for the infra lightweight concrete？\"', '\"How does the Sinnstiftung look like?\"', '\"What\\'s the advantage of using clay on the ceiling?\"', '\"Are there any alternative materials?\"', '\"Are there examples of a modern half timbered house?\"', '\"Can you show me an example of a modern half timbered house>\"', '\"Hi Zaha\"', '\"I\\'m sorry that I don\\'t have so much idea.\"', '\"I think there should be more open studios inside the building which are not assigned to a particular professor, but available for every student to spend time and participate in zoom meetings.\"', '\"I think it should be more inviting compared to current architecture faculties. For example, exhibition spaces on the ground floor or a cafe.\"', '\"I like the brick appearance on the existing building.\"', '\"It is a very central place, there can be huge windows to look outside.\"', '\"It can have a public plaza in the front.\"', '\"There should be greenery aroud the building, it would be nice to have realationship with nature.\"', '\"The design does not have to be a perfect square block, it can have many access points.\"', '\"It can also have connections with other buildings.\"', '\"Such as bridges\"', '\"There should be many student gathering areas.\"', '\"The seminar rooms should be accesible by many people in the building-\"', '\"There should be a makerspace for model making.\"', '\"There shouldn\\'t be too many lecture halls.\"', '\"Wheelcahir accesibility is very imporant in this building.\"', '\"that was all of my ideas.\"', '\"Thank you!\"', '\"Do you have any ideas?\"', '\"Is there anything we should take into consideration?\"', '\"But it can be a very challenging goal to achieve.\"', '\"It is definitely important, how can we achieve this goal?\"', '\"Are they giving interesting ideas?\"', '\"\"', '\"Do you use every idea?\"', '\"Thank you\"', '\"Hi Zaha\"', '\"Fine, thanks. What do you need to know?\"', '\"More natural light in the interior space. Facilities and features for students, such as selling automats with drinks and food. Free drink water. Spaces to meet in group\"', '\"Yes, sustainability, equity and democracy\"', '\"Yes, modern light-weithed clean\"', '\"Yes, Spaces for the meetings in groups. \"', '\"No\"', '\"CODE\"', '\"Have you ever designed something like this before?\"', '\"Do you have any reference for the desin?\"', '\"I think that a good architecture school should have a big tables and a lot of light, It should look like an atelier\"', '\"The collective space should be the core of the building, sharing ideas and networking are keypoints.\"', '\"and don\\'t forget about the coffe machine! This is the real important part\"', '\"\"', '\"\"', '\"\"', '\"Can you tell me some interesting reference for the design?\"', '\"Yes it would be great! What´s the tile?\"', '\"thanks to your database do you know all the architects who have ever existed and their respective works?\"', '\"Can you tell a good building from a bad one?\"', '\"What do you think about Alvaro Siza Architect?\"', '\"Are you able to draw?\"', '\"Can you show me some of your drawings?\"', '\"who have you worked with in the past?\"', '\"Can you be more specific?\"', '\"I think that Zaha Hadid design terrible building\"', '\"Hello Zaha, nice to meet you! I\\'m glad to be chosen to participate in this design evaluation. In my opinion the new faculty building should definitely have a couple studio spaces (like for the professorship Auer, Petzold or Dörfler). The building could have a positive impact on the environment by having an extensively planted green roof and probably a system that manages to facilitate the building without extrernal cooling or heating. That would be pretty cool. I would also love to see a building that communicates towards the main TUM campus, because the building as it is doesn\\'t really open up to the Theresienstraße. As many Civil and Environmental Engineers work in the Nordbau, it should definitely have a connection to that department as well. The TUM doesn\\'t have a timber building at the Stammgelände, so it would be nice to see that the TUM actually cares about progressional architecture and provides us with a new timber faculty building. A little place to get coffee within the building and to look into the green would also be nice. \"', '\"big rooms without limitation \"', '\"hide in the environment\"', '\"no\"', '\"that is an good idea\"', '\"it should with more glass fassade \"', '\"what you mean about the values\"', '\"buildings should be a part of communicate\"', '\"modern\"', '\"finish?\"', '\"Hey, I would like a building with community space\"', '\"space for eating, learning, working and gathering under open sky\"', '\"not too big but with huge windows and big studios\"', '\"Great Idea!\"', '\"I think its important to have meeting zones for informal exchange\"', '\"places where you can sit, also a kind of retreat where exchange can be discussed.\"', '\"durable materials, efficient use of materials that are less ecological, reuse of existing materials of remounted buildings\"', '\"the building should have connected spaces for workshop between students\"', '\"the building should have kinda isolated spaces that make the students collaborate in separated groups\"', '\"the building should have large lecture rooms for those lectures with many students registered\"', '\"the building should have relative small seminar rooms for those lectures with small groups of students\"', '\"the internal design of the building should have different architectural styles\"', '\"the construction of the building should consider the state of art construction technologies such as Additive Manufacturing in Construction\"', '\"the building should optimize the energy consumption\"', '\"the construction phase should be efficient and fast\"', '\"the design of the building should lead to the rethink of future architectural design\"', '\"each floor should have at least two toilets\"', '\"When will it be built?\"', '\"How long will it take_\"', '\"Do you know the budget?\"', '\"For how many users will it be?\"', '\"But how many people will be using it?\"', '\"I thought there is at least twice as many students\"', '\"Which rooms will be there?\"', '\"Will there be a cafeteria?\"', '\"Nice\"', '\"Which architect or an architectural office will be responsible for the design?\"', '\"Ahh, true. Could you tell me something more about you?\"', '\"Which projects have you done?\"', '\"For example?\"', '\"In which cities?\"', '\"Which building in Munich have you designed?\"', '\"Oh nice, I didnt know it was you\"', '\"Will the new building be similar to that one?\"', '\"Will there be something distinctive, individual for only this building?\"', '\"Will there be a rooftop garden?\"', '\"Do you plan some special sustainable solutions? If yes, which ones?\"', '\"Have you thought about making this building clima-neutral?\"', '\"Will it receive DGNB certificate?\"', '\"Can I do an internship within the planning process?\"', '\"Thats great, how to contact you in that matter?\"', '\"Stundentrooms should be included and worshopspaces are a necessity \"', '\"It should be fokused on student work which is mostly on computers and model work\"', '\"also it should be environmentally friendly and inlusive\"', '\"working in teams is essential for a collaboration in the student life so inputs for collective environments and meeting points like coffee stations, kitchens and similar things should be includet\"', '\"I would include workstations fp\"', '\"I would include workstations for individual use but how could we integrate this in a concept of the university \"', '\"?\"', '\"Personal and teamwork should be possible, but how do we differentiate between pulbic use and private use i this context\"', '\"The existing structure should be touched as little as possible. Reconstruction is consuming a lot of resources so most of the existing building should be reused.\"', '\"Is the existing structure suited for that?\"', '\"How many floors will the building have?\"', '\"I hope there will be some green plants in the building, plants always make people feel more comfortable\"', '\"Wil the building be a passive building or at least energy-efficient building?\"', '\"What measurement or technology will be used for energy-saving?\"', '\"Will the solar panels be used to produce electricity?\"', '\"How much percentage of electricity comsume can those solar panels cover?\"', '\"Will the solar panel be only on the roof? How many space is there?\"', '\"How does it look like? Will it in modern style or still match the other buildings around?\"', '\"How many rooms does the building have?\"', '\"Will there be a small library and some place for studing?\"', '\"Is it possible that it will be a wood building?\"', '\"I hope there can be some automatic control system for lighting or heating in winter\"', '\"Is there a cooling system?\"', '\"How does it cool the building? Is it central air-conditioner?\"', '\"Is a floor heating or cooling possible?\"', '\"Is a ceiling heating or cooling possible?\"', '\"Is a wall heating or cooling possible?\"', '\"I hope in office room or big classroom there can be sound absorber so that we can hear more clearly.\"', '\"\"', '\"The building should have spaces for the students to interact and hang out in their free time. Also it would be good to work with visual interactions as well. In addition i would prefer an industrial architecture.\"', '\"i think that would make sense\"', '\"it needs 4 floors but the scale of the excisting building works well in the urban context\"', '\"The building should be accessible to all students even those with disabilities. it should have studio spaces as well as offices for staff\"', '\"It should be an environmentally sustainable project that uses sustainable materials and building practices to create a building that runs in a sustainable way \"', '\"comfortable spaces and facilities for both students and staff so that they can relax when not working\"', '\"it should have a unique aesthetic while still relating to its surrounding cityscape\"', '\"it should accomadate 1400 students and have appropriate teaching spaces to accomadate this \"', '\"it should be 3-4 floors in height and have both stairs and elevators\"', '\"it should be 3000 m2\"', '\"there should be canteen spaces for people to make their own food\"', '\"the building should create an environment where the discussion and sharing of ideas is promoted and this should be evident in its form\"', '\"it should also have big windows\"', '\"it should create positive external spaces that have a positive impact on both the student population and the local community\"', '\"it has a library\"', '\"What do you think about my inp dear zaha where did you learn architectureut\"', '\"Where did learn architecture\"', '\"That\\'s great who were your teachers\"', '\"\"', '\"Who\\'s your favorite architect what\\'s your favorite building\"', '\"Are you married\"', '\"What are you doing tonight\"', '\"How about we meet later for a beer\"', '\"hello\"', '\"yes\"', '\"about the new architecture school\"', '\"I was wondering that the new school has big workshop and maybe some shops\"', '\"yes so that when we are hungry, we can buy some food.\"', '\"Yes and easy access to toilet\"', '\"and there should be some big place that people can communicate with each other\"', '\"I think it should be a city \\u200b\\u200blandmark.\"', '\"which can show the value of our univesity\"', '\"and it should be safe because we use our studio for a long time \"', '\"keep it sefe from thief\"', '\"and open to the block \"', '\"have a good communication with the neighbor\"', '\"and the ground floor should have a good realationship with the street \"', '\"like trees\"', '\"a beautiful courtyard is also good\"', '\"and we can see the beauty of different seasons\"', '\"And the space should show our history\"', '\"the space should be rich\"', '\"and different spaces\"', '\"and should be interesting\"', '\"and a if it possible the teachers can have chat with us \"', '\"not too high\"', '\"and a lot of students can stay inside\"', '\"that is it\"']\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# Load the model and the tokenizer from the downloaded files.\n",
        "# I added 'map_location=torch.device('cpu')' bcz I use only cpu\n",
        "model = torch.load(r\"/content/drive/MyDrive/src/my_model_3.pth\", map_location=torch.device('cpu'))\n",
        "tokenizer = torch.load(r\"/content/drive/MyDrive/src/my_tokenizer.pth\", map_location=torch.device('cpu'))\n",
        "\n",
        "all_sentence_nouns = []\n",
        "\n",
        "# Our input\n",
        "for sentence in client_message:\n",
        "  tokenized_sentence = tokenizer.encode(sentence)  # list of numbers represent each word\n",
        "  input_ids = torch.tensor([tokenized_sentence])  # I removed the .cuda() bcz I used only cpu on my computer\n",
        "\n",
        "\n",
        "  tag_values = ['DT', 'POS', 'NNS', 'VBG', 'CD', ';', 'JJS', 'NN', 'RP', '.', 'WP', 'PRP', 'CC', 'WRB', 'RBR', 'MD', 'VBZ', 'UH', 'FW', 'PDT',\n",
        "                'NNP', ':', 'JJ', 'JJR', 'RRB', '$', 'VB', ',', 'VBP', 'PRP$', 'NNPS', '``', 'IN', 'EX', 'TO', 'RB', 'VBN', 'RBS', 'WDT', 'LRB', 'VBD', 'WP$', 'PAD']\n",
        "\n",
        "  with torch.no_grad():\n",
        "      output = model(input_ids)\n",
        "\n",
        "  label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)\n",
        "\n",
        "  # join bpe split tokens\n",
        "  tokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
        "\n",
        "  new_tokens, new_labels, nouns_from_sentence = [] ,[], []\n",
        "\n",
        "  for token, label_idx in zip(tokens, label_indices[0]):\n",
        "      if token.startswith(\"##\"):\n",
        "          new_tokens[-1] = new_tokens[-1] + token[2:]\n",
        "      else:\n",
        "          new_labels.append(tag_values[label_idx])\n",
        "          new_tokens.append(token)\n",
        "\n",
        "  for token, label in zip(new_tokens, new_labels):\n",
        "      if 'NN' in label and '[SEP]' not in token and '[CLS]' not in token and '?' not in token:\n",
        "          nouns_from_sentence.append(token)\n",
        "\n",
        "  all_sentence_nouns.append(nouns_from_sentence) # [['noun1','noun2',..],[]]\n",
        "\n",
        "print(f'all_sentence_nouns = {all_sentence_nouns}')\n",
        "print(f'client_message = {client_message}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED4G8L6Bpyvl"
      },
      "source": [
        "# Second step\n",
        "We use smaller-LaBSE(Language-agnostic BERT Sentence Embedding) model to get the sentences embeddings.\n",
        "We have 3 options:\n",
        "1. Get the vector for *all* the sentence.\n",
        "2. Get the vector for a *concatenation string of the nouns* in the sentence.\n",
        "3. Get a vector *for each noun in the sentence* and sum the values for each category you get and then calc the avg of all the nouns in the sentence and return the max.\n",
        "\n",
        "For each option we check what category the sentence belong to (by calc the arithmetic distance between the vector that represent the sentence and the vectors that represent the categories).\n",
        "\n",
        "# The first option\n",
        "Get the vector for *all* the sentence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOyZfCFpDcC0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_text  # noqa\n",
        "import tensorflow_hub as hub\n",
        "from xlsxwriter import Workbook\n",
        "\n",
        "TRESHOLD = 0.22\n",
        "\n",
        "# Loading models from tfhub.dev\n",
        "encoder = hub.KerasLayer(\"https://tfhub.dev/jeongukjae/smaller_LaBSE_15lang/1\")\n",
        "preprocessor = hub.KerasLayer(\"https://tfhub.dev/jeongukjae/smaller_LaBSE_15lang_preprocess/1\")\n",
        "\n",
        "# Constructing model to encode texts into high-dimensional vectors\n",
        "sentences = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\"sentences\")\n",
        "encoder_inputs = preprocessor(sentences)\n",
        "sentence_representation = encoder(encoder_inputs)[\"pooled_output\"]\n",
        "normalized_sentence_representation = tf.nn.l2_normalize(sentence_representation, axis=-1)  # for cosine similarity\n",
        "model = tf.keras.Model(sentences, normalized_sentence_representation)\n",
        "\n",
        "# Start Algo\n",
        "\n",
        "index_category = {0:'Environment and climate resilience',1:'Mobility (transport)',2:'Local identity',3:'Future of work',4:'Land use'}\n",
        "\n",
        "output_excel = creating_excel()  # create an Excel file\n",
        "excel_index = 0\n",
        "\n",
        "temp = 0 # for break\n",
        "for sentence in client_message:\n",
        "  # Encoding the messages and the categories sentences.\n",
        "  messages_sentences = tf.constant([sentence])\n",
        "  categories_sentences = tf.constant([\"Environment and climate resilience\", \"Mobility (transport)\", \"Local identity\", \"Future of work\", \"Land use\"])\n",
        "\n",
        "  messages_embeds = model(messages_sentences)\n",
        "  categories_embeds = model(categories_sentences)\n",
        "\n",
        "  # Messages-categories similarity\n",
        "  result = tf.tensordot(messages_embeds, categories_embeds, axes=[[1], [1]])\n",
        "\n",
        "  # write the sentence in the excel\n",
        "  output_excel.at[excel_index, 'Sentence'] = sentence\n",
        "\n",
        "  for value in result: # result = [[3432 34234 234 324234 23]]\n",
        "    for i,v in enumerate(value): # for each number in the list\n",
        "      if float(v) > TRESHOLD: # needs to be change accorindg to the result from ChatGPT\n",
        "        output_excel.at[excel_index, 'Category'] = index_category.get(i) + ','\n",
        "\n",
        "  excel_index += 1\n",
        "  if temp > 100:\n",
        "    break\n",
        "  temp += 1\n",
        "\n",
        "output_excel.to_excel(\"Results.xlsx\", index=False)  # save the Excel file\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWFDEEvUoHaB"
      },
      "source": [
        "# The second option\n",
        "Get the vector for a *concatenation string of the nouns* in the sentence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81Q-7zojoGJq",
        "outputId": "ee005856-f5a4-4207-b232-2acf0cd120e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Excel Created\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_text  # noqa\n",
        "import tensorflow_hub as hub\n",
        "from xlsxwriter import Workbook\n",
        "\n",
        "TRESHOLD = 0.3\n",
        "\n",
        "# Loading models from tfhub.dev\n",
        "encoder = hub.KerasLayer(\"https://tfhub.dev/jeongukjae/smaller_LaBSE_15lang/1\")\n",
        "preprocessor = hub.KerasLayer(\"https://tfhub.dev/jeongukjae/smaller_LaBSE_15lang_preprocess/1\")\n",
        "\n",
        "# Constructing model to encode texts into high-dimensional vectors\n",
        "sentences = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\"sentences\")\n",
        "encoder_inputs = preprocessor(sentences)\n",
        "sentence_representation = encoder(encoder_inputs)[\"pooled_output\"]\n",
        "normalized_sentence_representation = tf.nn.l2_normalize(sentence_representation, axis=-1)  # for cosine similarity\n",
        "model = tf.keras.Model(sentences, normalized_sentence_representation)\n",
        "\n",
        "# Start Algo\n",
        "index_category = {0:'Environment and climate resilience',1:'Mobility (transport)',2:'Local identity',3:'Future of work',4:'Land use'}\n",
        "\n",
        "output_excel = creating_excel()  # create an Excel file\n",
        "excel_index = 0\n",
        "\n",
        "# temp = 0 # for break\n",
        "for nouns,sentence in zip(all_sentence_nouns,client_message):\n",
        "  \n",
        "  # print(f'nouns = {nouns}') # nouns = ['places', 'students', 'building']\n",
        "  # print(f'sentence = {sentence}') # \"I think there should be many various sitting..\"\n",
        "\n",
        "  # when list of nouns is empty, continue to the next iteration\n",
        "  if len(nouns) == 0:\n",
        "    continue\n",
        "\n",
        "  # creates a concatenated string of all nouns\n",
        "  conca_string = ' '.join(nouns)\n",
        "\n",
        "  # Encoding the messages and the categories sentences.\n",
        "  messages_sentences = tf.constant([conca_string])\n",
        "  categories_sentences = tf.constant([\"Environment and climate resilience\", \"Mobility (transport)\", \"Local identity\", \"Future of work\", \"Land use\"])\n",
        "\n",
        "  messages_embeds = model(messages_sentences)\n",
        "  categories_embeds = model(categories_sentences)\n",
        "\n",
        "  # Messages-categories similarity\n",
        "  result = tf.tensordot(messages_embeds, categories_embeds, axes=[[1], [1]])\n",
        "\n",
        "  # write the sentence in the excel\n",
        "  output_excel.at[excel_index, 'Sentence'] = sentence\n",
        "  output_excel.at[excel_index, 'Nouns'] = conca_string\n",
        "\n",
        "  category = ''\n",
        "  for value in result: # result = [[3432 34234 234 324234 23]]\n",
        "    for i,v in enumerate(value): # for each number in the list\n",
        "      if float(v) > TRESHOLD: # needs to be change accorindg to the result from ChatGPT\n",
        "        category += index_category.get(i) + ','\n",
        "    output_excel.at[excel_index, 'Category'] = category\n",
        "\n",
        "  excel_index += 1\n",
        "  if temp > 100:\n",
        "    break\n",
        "  temp += 1\n",
        "\n",
        "output_excel.to_excel(\"Results.xlsx\", index=False)  # save the Excel file\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuE9qsiE5VU-"
      },
      "source": [
        "# The third option\n",
        "Get a vector *for each noun in the sentence* and sum the values for each category you get and then calc the avg of all the nouns in the sentence and return the max:\n",
        "\n",
        "**example:**\n",
        "\n",
        "  sentence = \"I think there should be many various sitting and studying    places for students, both inside and outside of the building.\"\n",
        "\n",
        "  nouns = places students building\n",
        "\n",
        "  call the model on each noun -> we get [value1,value2,...,value5]\n",
        "\n",
        "  sum all the values for each categoty and then return the category with the max value.\n",
        "\n",
        "  \n",
        "\n",
        "smaller-LaBSE.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afTMBJ980aqG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_text  # noqa\n",
        "import tensorflow_hub as hub\n",
        "#from xlsxwriter import Workbook\n",
        "\n",
        "TRESHOLD = 0.22\n",
        "\n",
        "# Loading models from tfhub.dev\n",
        "encoder = hub.KerasLayer(\"https://tfhub.dev/jeongukjae/smaller_LaBSE_15lang/1\")\n",
        "preprocessor = hub.KerasLayer(\"https://tfhub.dev/jeongukjae/smaller_LaBSE_15lang_preprocess/1\")\n",
        "\n",
        "# Constructing model to encode texts into high-dimensional vectors\n",
        "sentences = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\"sentences\")\n",
        "encoder_inputs = preprocessor(sentences)\n",
        "sentence_representation = encoder(encoder_inputs)[\"pooled_output\"]\n",
        "normalized_sentence_representation = tf.nn.l2_normalize(sentence_representation, axis=-1)  # for cosine similarity\n",
        "model = tf.keras.Model(sentences, normalized_sentence_representation)\n",
        "\n",
        "# Start Algo\n",
        "index_category = {0:'Environment and climate resilience',1:'Mobility (transport)',2:'Local identity',3:'Future of work',4:'Land use'}\n",
        "\n",
        "output_excel = creating_excel()  # create an Excel file\n",
        "excel_index = 0\n",
        "sum_result_column = [0 for i in range(5)]\n",
        "\n",
        "temp = 0 # for break\n",
        "for nouns,sentence in zip(all_sentence_nouns,client_message):\n",
        "  \n",
        "  # print(f'nouns = {nouns}') # nouns = ['places', 'students', 'building']\n",
        "  # print(f'sentence = {sentence}') # \"I think there should be many various sitting..\"\n",
        "\n",
        "  # when list of nouns is empty\n",
        "  if len(nouns) == 0:\n",
        "    continue\n",
        "\n",
        "  # creates a concatenated string of all nouns\n",
        "  conca_string = ' '.join(nouns)\n",
        "\n",
        "  for noun in nouns:\n",
        "\n",
        "    # Encoding the messages and the categories sentences.\n",
        "    messages_sentences = tf.constant([noun])\n",
        "    categories_sentences = tf.constant([\"Environment and climate resilience\", \"Mobility (transport)\", \"Local identity\", \"Future of work\", \"Land use\"])\n",
        "\n",
        "    messages_embeds = model(messages_sentences)\n",
        "    categories_embeds = model(categories_sentences)\n",
        "\n",
        "    # Messages-categories similarity\n",
        "    result = tf.tensordot(messages_embeds, categories_embeds, axes=[[1], [1]])\n",
        "\n",
        "    # write the sentence in the excel\n",
        "    output_excel.at[excel_index, 'Sentence'] = sentence\n",
        "    output_excel.at[excel_index, 'Nouns'] = conca_string\n",
        "\n",
        "    for value in result: # result = [[3432 34234 234 324234 23]]\n",
        "      for i,v in enumerate(value): # for each number in the list\n",
        "        sum_result_column[i] += v\n",
        "\n",
        "  category = ''\n",
        "  for i,value in enumerate(sum_result_column):\n",
        "    if float(value) > TRESHOLD:\n",
        "      category += index_category.get(i) + ','\n",
        "  output_excel.at[excel_index, 'Category'] = category\n",
        "\n",
        "  print(f'temp = {temp}')\n",
        "  excel_index += 1\n",
        "  if temp > 60:\n",
        "    break\n",
        "  temp += 1\n",
        "\n",
        "output_excel.to_excel(\"Results.xlsx\", index=False)  # save the Excel file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9Cvsouu9GZS"
      },
      "source": [
        "# Supervised classification\n",
        "- Use ChatGPT API to classify the sentences to the right categories \n",
        "\n",
        "# Algorithm\n",
        "\n",
        "- Create a function that get a sentence as input and return a list of the nouns\n",
        "\n",
        "- Create a function that get a sentence as input and return the cos similarity between the sentence and the 5 categories \n",
        "\n",
        "- Create a function that get a sentence, nouns and cos similarity of the sentence and return the classification from Chat GPT for this sentence. Send a querry to ChatGPT with the sentence, the nouns of the sentence and the cos similarity of the sentence with the 5 categories.\n",
        "\n",
        "- Train a model using the classifier adaboost and the embedding TF IDF to get the best result. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "px0dAGsDL9bU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "def get_nouns(sentence):\n",
        "    # Load the model and the tokenizer from the downloaded files.\n",
        "    # I added 'map_location=torch.device('cpu')' bcz I use only cpu\n",
        "    model = torch.load(r\"/content/drive/MyDrive/src/my_model_3.pth\", map_location=torch.device('cpu'))\n",
        "    tokenizer = torch.load(r\"/content/drive/MyDrive/src/my_tokenizer.pth\", map_location=torch.device('cpu'))\n",
        "\n",
        "    # Our input\n",
        "    tokenized_sentence = tokenizer.encode(sentence)  # list of numbers represent each word\n",
        "    input_ids = torch.tensor([tokenized_sentence])  # I removed the .cuda() bcz I used only cpu on my computer\n",
        "\n",
        "\n",
        "    tag_values = ['DT', 'POS', 'NNS', 'VBG', 'CD', ';', 'JJS', 'NN', 'RP', '.', 'WP', 'PRP', 'CC', 'WRB', 'RBR', 'MD', 'VBZ', 'UH', 'FW', 'PDT',\n",
        "                'NNP', ':', 'JJ', 'JJR', 'RRB', '$', 'VB', ',', 'VBP', 'PRP$', 'NNPS', '``', 'IN', 'EX', 'TO', 'RB', 'VBN', 'RBS', 'WDT', 'LRB', 'VBD', 'WP$', 'PAD']\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_ids)\n",
        "\n",
        "    label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)\n",
        "\n",
        "    # join bpe split tokens\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
        "\n",
        "    new_tokens, new_labels, nouns_from_sentence = [] ,[], []\n",
        "\n",
        "    for token, label_idx in zip(tokens, label_indices[0]):\n",
        "        if token.startswith(\"##\"):\n",
        "            new_tokens[-1] = new_tokens[-1] + token[2:]\n",
        "        else:\n",
        "            new_labels.append(tag_values[label_idx])\n",
        "            new_tokens.append(token)\n",
        "    ans = \"\"\n",
        "    for token, label in zip(new_tokens, new_labels):\n",
        "        ans+=\"{}\\t{}\".format(label, token)\n",
        "        ans+=\"\\n\"\n",
        "    nouns_from_sentence = re.findall(r'NN\\w*\\s+(\\w+)', ans)\n",
        "\n",
        "    return nouns_from_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXLQuu2DOBzo",
        "outputId": "6462d510-1256-4739-c499-7993a1992716"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['places', 'students', 'building']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example of using the function\n",
        "get_nouns(\"I think there should be many various sitting and studying places for students, both inside and outside of the building.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e38gRWFU2Sia"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_text  # noqa\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "\n",
        "def get_c_similarity(sentence):\n",
        "    # Loading models from tfhub.dev\n",
        "    encoder = hub.KerasLayer(\"https://tfhub.dev/jeongukjae/smaller_LaBSE_15lang/1\")\n",
        "    preprocessor = hub.KerasLayer(\"https://tfhub.dev/jeongukjae/smaller_LaBSE_15lang_preprocess/1\")\n",
        "\n",
        "    # Constructing model to encode texts into high-dimensional vectors\n",
        "    sentences = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\"sentences\")\n",
        "    encoder_inputs = preprocessor(sentences)\n",
        "    sentence_representation = encoder(encoder_inputs)[\"pooled_output\"]\n",
        "    normalized_sentence_representation = tf.nn.l2_normalize(sentence_representation, axis=-1)  # for cosine similarity\n",
        "    model = tf.keras.Model(sentences, normalized_sentence_representation)\n",
        "\n",
        "    # Encoding sentences.\n",
        "    CheckSentence = tf.constant([sentence])\n",
        "    Categories = tf.constant([\"Environment and climate resilience\", \"Mobility (transport)\", \"Local identity\", \"Future of work\", \"Land use\"])\n",
        "\n",
        "    sentence_embeds = model(CheckSentence)\n",
        "    categories_embeds = model(Categories)\n",
        "\n",
        "    # sentence-categories similarity to list\n",
        "    tensor_list = tf.tensordot(sentence_embeds, categories_embeds, axes=[[1], [1]]).numpy().tolist()\n",
        "    \n",
        "    return tensor_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfcza3S2Wgs7",
        "outputId": "a054a08b-d378-4995-bdd1-a79c9873f8af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[0.20263248682022095,\n",
              "  0.06531611829996109,\n",
              "  0.0811031311750412,\n",
              "  0.1793404370546341,\n",
              "  0.0731455385684967]]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example of using the function\n",
        "get_c_similarity(\"I think there should be many various sitting and studying places for students, both inside and outside of the building.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9N-aMj7KwK4"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RyVbMEpVKkj"
      },
      "outputs": [],
      "source": [
        "!pip install rollbar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrJ7t0JP9FzG"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import rollbar\n",
        "rollbar.init('3524a066b047491b9d777810d89dbfe4', 'testenv')\n",
        "# Set up the OpenAI API client\n",
        "openai.api_key = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KoHXTfpLB1F"
      },
      "outputs": [],
      "source": [
        "def ask_chatgpt(question):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model='gpt-3.5-turbo',\n",
        "        n=1,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a chatbot\"},\n",
        "            {\"role\": \"user\", \"content\": question},\n",
        "        ])\n",
        "\n",
        "    result = ''\n",
        "    for choice in response.choices:\n",
        "     result += choice.message.content\n",
        "     return (result)\n",
        "\n",
        "def gpt_ans(test_sentence, nouns, c_similarity_list):\n",
        " query = f\"\"\"for this sentance: {test_sentence} the nouns are: {nouns} and the cos similarity is: {c_similarity_list} Now I want you to tell me,\n",
        " given the nouns in the sentence and the cos similarity, for each of the five key areas, does the sentence fall. please write your answer in the following format:\n",
        " 1. Environment and climate resilience: Yes/No\n",
        " 2. Mobility (transport): Yes/No\n",
        " 3. local identity: Yes/No\n",
        " 4. future of work: Yes/No\n",
        " 5. land use: Yes/No\n",
        " if you cannot provide an answer for the five key areas, return 'No' for each key area with the format above.\n",
        " if there are no nouns in the sentence, still classify each of the five key areas, does the sentence fall with the format above\"\"\"\n",
        " try:\n",
        "     return ask_chatgpt(query)\n",
        " except Exception as e:\n",
        "     # monitor exception using Rollbar\n",
        "     rollbar.report_exc_info()\n",
        "     return e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Rhc_W20KLrD7",
        "outputId": "a9e8458b-513a-42f9-e634-09287e274edb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1. Environment and climate resilience: No\\n2. Mobility (transport): No\\n3. local identity: No\\n4. future of work: No\\n5. land use: No'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example of using the function\n",
        "sen = \"I think there should be many various sitting and studying places for students, both inside and outside of the building.\"\n",
        "nouns = get_nouns(sen)\n",
        "c_sim = get_c_similarity(sen)\n",
        "example = gpt_ans(sen, nouns, c_sim)\n",
        "example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Apmw4QHjkdfM",
        "outputId": "1ad21d54-cc3f-4188-d8be-69547adebef4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data length: 301\n",
            "Test data length: 76\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into train and test sets\n",
        "train_data, test_data = train_test_split(client_message, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Train data length:\", len(train_data))\n",
        "print(\"Test data length:\", len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAww2x2al-Xx"
      },
      "outputs": [],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fz16RBrHJTQe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def parse_and_append(output, sentence, df):\n",
        "    lines = output.strip().split('\\n')\n",
        "    classes = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Only process lines starting with a number followed by a period\n",
        "        if len(line) >= 2 and line[0].isdigit() and line[1] == '.':\n",
        "            key_area, value = line[2:].split(':')\n",
        "            key_area = key_area.strip()\n",
        "            value = value.strip()\n",
        "\n",
        "            if value.lower() == 'yes':\n",
        "                classes.append(key_area)\n",
        "\n",
        "    if not classes:\n",
        "        classes.append('None')\n",
        "\n",
        "    new_rows = pd.DataFrame({\"sentence\": [sentence] * len(classes), \"class\": classes})\n",
        "    df = pd.concat([df, new_rows], ignore_index=True)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "dKDcH9nUWgjo",
        "outputId": "17e615f4-0caf-41d4-e8e3-98b18f494b0f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a3e7b478-6216-4418-8612-e95e991a3494\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I think there should be many various sitting a...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3e7b478-6216-4418-8612-e95e991a3494')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a3e7b478-6216-4418-8612-e95e991a3494 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a3e7b478-6216-4418-8612-e95e991a3494');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            sentence class\n",
              "0  I think there should be many various sitting a...  None"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example of using the function\n",
        "example_df = pd.DataFrame(columns=[\"sentence\", \"class\"])\n",
        "parse_example = parse_and_append(example, sen, example_df)\n",
        "parse_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ne0M6jtwho1D"
      },
      "outputs": [],
      "source": [
        "# Create an empty DataFrame with the desired column names\n",
        "train_df = pd.DataFrame(columns=[\"sentence\", \"class\"])\n",
        "\n",
        "# Process each sentence in the list\n",
        "for sen in train_data:\n",
        "    nouns = get_nouns(sen)\n",
        "    c_similarity = get_c_similarity(sen)\n",
        "    output = gpt_ans(sen, nouns, c_similarity)\n",
        "    # print(output)\n",
        "    train_df = parse_and_append(output, sen, train_df)\n",
        "\n",
        "# Display the DataFrame\n",
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jB5njAVeIsZ"
      },
      "outputs": [],
      "source": [
        "# Create an empty DataFrame with the desired column names\n",
        "test_df = pd.DataFrame(columns=[\"sentence\", \"class\"])\n",
        "\n",
        "# Process each sentence in the list\n",
        "for sen in test_data:\n",
        "    nouns = get_nouns(sen)\n",
        "    c_similarity = get_c_similarity(sen)\n",
        "    output = gpt_ans(sen, nouns, c_similarity)\n",
        "    # print(output)\n",
        "    test_df = parse_and_append(output, sen, train_df)\n",
        "\n",
        "# Display the DataFrame\n",
        "test_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7OKzVzv_S0Q"
      },
      "source": [
        "Here we split the data to features and labels for the train and the test "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NadZ68pdl3ef"
      },
      "outputs": [],
      "source": [
        "# Create empty lists to hold the sentences and classes\n",
        "sentences_train = []\n",
        "classes_train = []\n",
        "\n",
        "# Iterate over the rows in the DataFrame\n",
        "for index, row in train_df.iterrows():\n",
        "    # Add the sentence and class to their respective lists\n",
        "    sentences_train.append(row[\"sentence\"])\n",
        "    classes_train.append(row[\"class\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrzkFjvzm4m9"
      },
      "outputs": [],
      "source": [
        "# Create empty lists to hold the sentences and classes\n",
        "sentences_test = []\n",
        "classes_test = []\n",
        "\n",
        "# Iterate over the rows in the DataFrame\n",
        "for index, row in test_df.iterrows():\n",
        "    # Add the sentence and class to their respective lists\n",
        "    sentences_test.append(row[\"sentence\"])\n",
        "    classes_test.append(row[\"class\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjePJAr4-9CL"
      },
      "source": [
        "#Build the model\n",
        "In here we train the model where the labels are based on the chatGPT results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0KX7vVGnW8g"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Create TF-IDF embeddings for the sentences\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform(sentences_train)\n",
        "X_test = vectorizer.transform(sentences_test)\n",
        "\n",
        "# Encode the class labels\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(classes_train)\n",
        "y_test = le.transform(classes_test)\n",
        "\n",
        "# Train the Adaboost classifier on the training data\n",
        "clf = AdaBoostClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Use the trained classifier to predict the classes for the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}